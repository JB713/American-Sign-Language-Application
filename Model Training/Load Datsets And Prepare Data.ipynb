{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data, process and save as numpy array files\n",
    "\n",
    "Load data and create numpy array files to test in google colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images and save to numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images, process them(resize and change between rgb and grayscale), and add them to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:01<00:00, 75.05it/s]\n",
      "100%|██████████| 111/111 [00:02<00:00, 44.29it/s]\n",
      "100%|██████████| 111/111 [00:01<00:00, 100.29it/s]\n",
      "100%|██████████| 111/111 [00:04<00:00, 24.51it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 142.86it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 138.45it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 145.18it/s]\n",
      "100%|██████████| 111/111 [00:03<00:00, 30.24it/s]\n",
      "100%|██████████| 111/111 [00:03<00:00, 29.89it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 144.16it/s]\n",
      "100%|██████████| 111/111 [00:03<00:00, 31.47it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 138.36it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 142.24it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 130.41it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 139.44it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 126.20it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 139.36it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 141.54it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 127.86it/s]\n",
      "100%|██████████| 111/111 [00:03<00:00, 28.28it/s]\n",
      "100%|██████████| 111/111 [00:04<00:00, 27.08it/s]\n",
      "100%|██████████| 111/111 [00:03<00:00, 30.70it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 136.01it/s]\n",
      "100%|██████████| 111/111 [00:00<00:00, 132.78it/s]\n"
     ]
    }
   ],
   "source": [
    "alphabet = ['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']\n",
    "\n",
    "train_image = []\n",
    "labels = []\n",
    "\n",
    "for letter in alphabet:\n",
    "    for i in tqdm([*range(1,112)]):\n",
    "        img_path = f'new_dataset/train/{letter}/{letter}{i}.jpg'\n",
    "        img = image.load_img(img_path, target_size=(100, 100, 1), color_mode=\"grayscale\")\n",
    "        img = image.img_to_array(img)\n",
    "        img = img/255\n",
    "        train_image.append(img)\n",
    "        labels = np.append(labels, letter)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image arrays to numpy array\n",
    "X = np.array(train_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = labels['Image Value'].values\n",
    "y = labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cat = to_categorical(encoded_y_train)\n",
    "y_test_cat = to_categorical(encoded_y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save image arrays as numpy array files for easy transport and re-use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"y_test\": shape (2131, 100, 100, 1), type \"<f4\">"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save as h5py file - not tested\n",
    "\n",
    "import h5py\n",
    "\n",
    "f = h5py.File(\"X_train_array.hdf5\", \"w\")\n",
    "f.create_dataset(\"X_train\", data = X_train, compression=\"gzip\")\n",
    "f = h5py.File(\"y_train_array.hdf5\", \"w\")\n",
    "f.create_dataset(\"y_train\", data = X_train, compression=\"gzip\")\n",
    "f = h5py.File(\"X_test_array.hdf5\", \"w\")\n",
    "f.create_dataset(\"X_test\", data = X_train, compression=\"gzip\")\n",
    "f = h5py.File(\"y_test_array.hdf5\", \"w\")\n",
    "f.create_dataset(\"y_test\", data = X_train, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as npy file\n",
    "\n",
    "from numpy import save\n",
    "\n",
    "save('X_train.npy', X_train)\n",
    "save('y_train.npy', y_train_cat)\n",
    "save('X_test.npy', X_test)\n",
    "save('y_test.npy', y_test_cat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mldata] *",
   "language": "python",
   "name": "conda-env-mldata-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
