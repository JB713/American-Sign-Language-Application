{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Deep Learning\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg19 import (\n",
    "    VGG19, \n",
    "    preprocess_input, \n",
    "    decode_predictions\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Ensure consistency across runs\n",
    "from numpy.random import seed\n",
    "import random\n",
    "seed(2)\n",
    "import tensorflow\n",
    "\n",
    "# Imports to view data\n",
    "import cv2\n",
    "from glob import glob\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Visualization\n",
    "from keras.utils import print_summary\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Utils\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import getenv\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "# Image Preprocessing\n",
    "from skimage.filters import sobel, scharr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variable Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'C:/Bootcamp/Homework/proj3-team04/Model Training/asl_alphabet_train/asl_alphabet_train'\n",
    "TEST_DIR = 'C:/Bootcamp/Homework/proj3-team04/Model Training/asl_alphabet_test/asl_alphabet_test'\n",
    "CUSTOM_TEST_DIR = '../input/asl-alphabet-test/asl-alphabet-test'\n",
    "CLASSES = [folder[len(TRAIN_DIR) + 1:] for folder in glob(TRAIN_DIR + '/*')]\n",
    "CLASSES.sort()\n",
    "\n",
    "TARGET_SIZE = (64, 64)\n",
    "TARGET_DIMS = (64, 64, 3) # add channel for RGB\n",
    "N_CLASSES = 29\n",
    "VALIDATION_SPLIT = 0.1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Model saving for easier local iterations\n",
    "MODEL_DIR = 'C:/Bootcamp/Homework/proj3-team04/Model Training/'\n",
    "MODEL_PATH = MODEL_DIR + '/cnn-model.h5'\n",
    "MODEL_WEIGHTS_PATH = MODEL_DIR + '/cnn-model.weights.h5'\n",
    "MODEL_SAVE_TO_DISK = 'C:/Bootcamp/Homework/proj3-team04/Model Training/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    '''Function that will be implied on each input. The function\n",
    "    will run after the image is resized and augmented.\n",
    "    The function should take one argument: one image (Numpy tensor\n",
    "    with rank 3), and should output a Numpy tensor with the same\n",
    "    shape.'''\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=5)\n",
    "    return sobely\n",
    "\n",
    "def make_generator(options):\n",
    "    '''Creates two generators for dividing and preprocessing data.'''\n",
    "    validation_split = options.get('validation_split', 0.0)\n",
    "    preprocessor = options.get('preprocessor', None)\n",
    "    data_dir = options.get('data_dir', TRAIN_DIR)\n",
    "\n",
    "    augmentor_options = {\n",
    "        'samplewise_center': True,\n",
    "        'samplewise_std_normalization': True,\n",
    "    }\n",
    "    if validation_split is not None:\n",
    "        augmentor_options['validation_split'] = validation_split\n",
    "    \n",
    "    if preprocessor is not None:\n",
    "        augmentor_options['preprocessing_function'] = preprocessor\n",
    "    \n",
    "    flow_options = {\n",
    "        'target_size': TARGET_SIZE,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'shuffle': options.get('shuffle', None),\n",
    "        'subset': options.get('subset', None),\n",
    "    }\n",
    "\n",
    "    data_augmentor = ImageDataGenerator(**augmentor_options)\n",
    "    return data_augmentor.flow_from_directory(data_dir, **flow_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to reprocess? True\n"
     ]
    }
   ],
   "source": [
    "def load_model_from_disk():\n",
    "    '''A convenience method for re-running certain parts of the\n",
    "    analysis locally without refitting all the data.'''\n",
    "    model_file = Path(MODEL_PATH)\n",
    "    model_weights_file = Path(MODEL_WEIGHTS_PATH)\n",
    "                      \n",
    "    if model_file.is_file() and model_weights_file.is_file():\n",
    "        print('Retrieving model from disk...')\n",
    "        model = load_model(model_file.__str__())\n",
    "                      \n",
    "        print('Loading CNN model weights from disk...')\n",
    "        model.load_weights(model_weights_file)\n",
    "        return model\n",
    "    \n",
    "    return None\n",
    "\n",
    "CNN_MODEL = load_model_from_disk()\n",
    "REPROCESS_MODEL = (CNN_MODEL is None)\n",
    "\n",
    "print('Need to reprocess? {}'.format(REPROCESS_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(save=False):\n",
    "    print('Building model afresh...')\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=4, strides=1, activation='relu', input_shape=TARGET_DIMS))\n",
    "    model.add(Conv2D(64, kernel_size=4, strides=2, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=1, activation='relu'))\n",
    "    model.add(Conv2D(128, kernel_size=4, strides=2, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(256, kernel_size=4, strides=1, activation='relu'))\n",
    "    model.add(Conv2D(256, kernel_size=4, strides=2, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(N_CLASSES, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    if save: model.save(MODEL_PATH)\n",
    "        \n",
    "    return model\n",
    "\n",
    "# if REPROCESS_MODEL:\n",
    "#     CNN_MODEL = build_model(save=MODEL_SAVE_TO_DISK)\n",
    "\n",
    "# print_summary(CNN_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 61, 61, 64)        3136      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 29, 29, 64)        65600     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 29, 29, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 26, 26, 128)       131200    \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 12, 12, 128)       262272    \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 9, 9, 256)         524544    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 3, 3, 256)         1048832   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               1180160   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 29)                14877     \n",
      "=================================================================\n",
      "Total params: 3,230,621\n",
      "Trainable params: 3,230,621\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78300 images belonging to 29 classes.\n",
      "Found 8700 images belonging to 29 classes.\n",
      "WARNING:tensorflow:From <ipython-input-36-66ca04063811>:14: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/5\n",
      "1224/1224 [==============================] - 1880s 2s/step - loss: 1.2814 - accuracy: 0.5890 - val_loss: 0.8117 - val_accuracy: 0.7220\n",
      "Epoch 2/5\n",
      "1224/1224 [==============================] - 1736s 1s/step - loss: 0.3837 - accuracy: 0.8681 - val_loss: 0.6793 - val_accuracy: 0.8141\n",
      "Epoch 3/5\n",
      "1224/1224 [==============================] - 1703s 1s/step - loss: 0.2551 - accuracy: 0.9130 - val_loss: 0.6580 - val_accuracy: 0.8017\n",
      "Epoch 4/5\n",
      "1224/1224 [==============================] - 1586s 1s/step - loss: 0.1998 - accuracy: 0.9326 - val_loss: 0.6639 - val_accuracy: 0.8257\n",
      "Epoch 5/5\n",
      "1224/1224 [==============================] - 1569s 1s/step - loss: 0.1770 - accuracy: 0.9427 - val_loss: 0.5358 - val_accuracy: 0.8494\n",
      "Fitting the model took ~8483 second(s).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension 1</th>\n",
       "      <th>Dimension 2</th>\n",
       "      <th>Dimension 3</th>\n",
       "      <th>Dimension 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2304</td>\n",
       "      <td>512.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>512</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Dimension 1  Dimension 2  Dimension 3  Dimension 4\n",
       "0             4          4.0          3.0         64.0\n",
       "1            64          NaN          NaN          NaN\n",
       "2             4          4.0         64.0         64.0\n",
       "3            64          NaN          NaN          NaN\n",
       "4             4          4.0         64.0        128.0\n",
       "5           128          NaN          NaN          NaN\n",
       "6             4          4.0        128.0        128.0\n",
       "7           128          NaN          NaN          NaN\n",
       "8             4          4.0        128.0        256.0\n",
       "9           256          NaN          NaN          NaN\n",
       "10            4          4.0        256.0        256.0\n",
       "11          256          NaN          NaN          NaN\n",
       "12         2304        512.0          NaN          NaN\n",
       "13          512          NaN          NaN          NaN\n",
       "14          512         29.0          NaN          NaN\n",
       "15           29          NaN          NaN          NaN"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_generator_for(subset):\n",
    "    '''Create a generator for the training or validation set.'''\n",
    "    generator_options = dict(\n",
    "        validation_split=VALIDATION_SPLIT,\n",
    "        shuffle=True,\n",
    "        subset=subset,\n",
    "        preprocessor=preprocess_image,\n",
    "    )\n",
    "    return make_generator(generator_options)\n",
    "\n",
    "\n",
    "def fit_model(model, train_generator, val_generator, save=False):\n",
    "    '''Fit the model with the training and validation generators.'''    \n",
    "    history = model.fit_generator(train_generator, epochs=5, validation_data=val_generator)\n",
    "    \n",
    "    if save: model.save_weights(MODEL_WEIGHTS_PATH)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "CNN_TRAIN_GENERATOR = make_generator_for('training')\n",
    "CNN_VAL_GENERATOR = make_generator_for('validation')\n",
    "\n",
    "HISTORY = None\n",
    "if REPROCESS_MODEL:\n",
    "    start_time = time.time()\n",
    "    HISTORY = fit_model(CNN_MODEL, CNN_TRAIN_GENERATOR, CNN_VAL_GENERATOR, save=MODEL_SAVE_TO_DISK)\n",
    "    print('Fitting the model took ~{:.0f} second(s).'.format(time.time() - start_time))\n",
    "\n",
    "\n",
    "columns=['Dimension 1', 'Dimension 2', 'Dimension 3', 'Dimension 4']\n",
    "pd.DataFrame(data=[x.shape for x in CNN_MODEL.weights], columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('test_model_1.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(generator):\n",
    "    start_time = time.time()\n",
    "    evaluations = CNN_MODEL.evaluate_generator(generator)\n",
    "    for i in range(len(CNN_MODEL.metrics_names)):\n",
    "        print(\"{}: {:.2f}%\".format(\n",
    "            CNN_MODEL.metrics_names[i], evaluations[i] * 100))\n",
    "    print('Took {:.0f} seconds to evaluate this set.'.format(\n",
    "        time.time() - start_time))\n",
    "\n",
    "    start_time = time.time()\n",
    "    predictions = CNN_MODEL.predict_generator(generator)\n",
    "    print('Took {:.0f} seconds to get predictions on this set.'.format(\n",
    "        time.time() - start_time))\n",
    "\n",
    "    y_pred = np.argmax(predictions, axis=1)\n",
    "    y_true = generator.classes\n",
    "    return dict(y_pred=y_pred, y_true=y_true)\n",
    "\n",
    "\n",
    "def evaluate_validation_dataset():\n",
    "    gen_options = dict(\n",
    "        validation_split=0.1,\n",
    "        data_dir=TRAIN_DIR,\n",
    "        shuffle=False,\n",
    "        subset='validation',\n",
    "        preprocessor=preprocess_image,\n",
    "    )\n",
    "    val_gen = make_generator(gen_options)\n",
    "    return evaluate_model(val_gen)\n",
    "\n",
    "\n",
    "def evaluate_test_dataset():\n",
    "    gen_options = dict(\n",
    "        validation_split=0.0,\n",
    "        data_dir=TEST_DIR,\n",
    "        shuffle=False,\n",
    "        preprocessor=preprocess_image,\n",
    "    )\n",
    "    test_gen = make_generator(gen_options)\n",
    "    return evaluate_model(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8700 images belonging to 29 classes.\n",
      "WARNING:tensorflow:From <ipython-input-38-f0fbf6e198a9>:3: Model.evaluate_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.evaluate, which supports generators.\n",
      "loss: 53.58%\n",
      "accuracy: 84.94%\n",
      "Took 42 seconds to evaluate this set.\n",
      "WARNING:tensorflow:From <ipython-input-38-f0fbf6e198a9>:11: Model.predict_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.predict, which supports generators.\n",
      "Took 45 seconds to get predictions on this set.\n"
     ]
    }
   ],
   "source": [
    "CNN_VALIDATION_SET_EVAL = evaluate_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.74      0.87      0.80       300\n",
      "           B       0.89      0.99      0.94       300\n",
      "           C       0.98      0.98      0.98       300\n",
      "           D       0.97      0.92      0.94       300\n",
      "           E       0.63      0.86      0.73       300\n",
      "           F       1.00      0.98      0.99       300\n",
      "           G       0.99      0.88      0.93       300\n",
      "           H       0.89      0.99      0.94       300\n",
      "           I       0.84      0.66      0.74       300\n",
      "           J       1.00      0.99      1.00       300\n",
      "           K       0.91      0.91      0.91       300\n",
      "           L       0.90      0.99      0.94       300\n",
      "           M       0.85      0.79      0.82       300\n",
      "           N       0.76      0.61      0.68       300\n",
      "           O       1.00      0.71      0.83       300\n",
      "           P       0.99      0.97      0.98       300\n",
      "           Q       0.97      0.99      0.98       300\n",
      "           R       0.88      0.90      0.89       300\n",
      "           S       0.82      0.85      0.83       300\n",
      "           T       0.81      0.65      0.72       300\n",
      "           U       0.75      0.73      0.74       300\n",
      "           V       0.52      0.46      0.49       300\n",
      "           W       0.56      0.78      0.65       300\n",
      "           X       0.68      0.59      0.63       300\n",
      "           Y       0.80      0.98      0.88       300\n",
      "           Z       0.79      0.88      0.83       300\n",
      "         del       0.99      0.99      0.99       300\n",
      "     nothing       0.93      0.74      0.82       300\n",
      "       space       0.99      0.99      0.99       300\n",
      "\n",
      "    accuracy                           0.85      8700\n",
      "   macro avg       0.86      0.85      0.85      8700\n",
      "weighted avg       0.86      0.85      0.85      8700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(**CNN_VALIDATION_SET_EVAL, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n"
     ]
    }
   ],
   "source": [
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
