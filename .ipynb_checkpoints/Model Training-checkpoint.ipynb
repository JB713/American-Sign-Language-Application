{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Image Name</th>\n",
       "      <th>Image Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Below_A (1)</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Front_A (1)</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Left_A (1)</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Right_A (1)</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Below_A (2)</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Image Name Image Value\n",
       "0           0  Below_A (1)           A\n",
       "1           1  Front_A (1)           A\n",
       "2           2   Left_A (1)           A\n",
       "3           3  Right_A (1)           A\n",
       "4           4  Below_A (2)           A"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Data file from Data Wrangling Process\n",
    "\n",
    "df = pd.read_csv('Image Values.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply pandas.get_dummies to convert categorical data to numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical_cols = ['A','B','C','D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.get_dummies(df,columns = categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "\n",
    "# from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.preprocessing import image\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from keras.utils import to_categorical\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dependencies\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "# from tensorflow import keras\n",
    "\n",
    "# from tensorflow.keras.applications.vgg19 import (\n",
    "#     VGG19, \n",
    "#     preprocess_input, \n",
    "#     decode_predictions\n",
    "# )\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from keras.layers import Conv2D, MaxPooling2D\n",
    "# tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4160/4160 [00:15<00:00, 271.31it/s]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('Image Values.csv')\n",
    "\n",
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    image_name = df['Image Name'][i]\n",
    "    img = f'C:/Bootcamp/Homework/proj3-team04/HGM-4/All Images Grayscale/JPEG/{image_name}.jpg'\n",
    "    img = image.load_img(img,target_size=(28,28,1),color_mode = \"grayscale\")\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255\n",
    "    train_image.append(img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image arrays to numpy array\n",
    "\n",
    "X = np.array(train_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=train['Image Value'].values\n",
    "y = pd.get_dummies(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_inputs = 4160\n",
    "# num_hidden_units = 1641\n",
    "# num_classes = 26\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = pd.get_dummies(y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_cat = pd.get_dummies(y_train).values\n",
    "# y_test_cat = pd.get_dummies(y_test).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3328, 26)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4160, 28, 28, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(26, kernel_size=(3, 3),activation='relu',input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(26, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# dense_layer = Dense(units = num_hidden_units, input_dim = num_inputs, activation = 'relu')\n",
    "# output_layer = Dense(units = 26, activation ='sigmoid')\n",
    "# model.add(dense_layer)\n",
    "# model.add(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 26)        260       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 64)        15040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 26)                3354      \n",
      "=================================================================\n",
      "Total params: 1,198,430\n",
      "Trainable params: 1,198,430\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "104/104 [==============================] - 6s 54ms/step - loss: 3.2565 - accuracy: 0.0430 - val_loss: 3.2334 - val_accuracy: 0.0601\n",
      "Epoch 2/10\n",
      "104/104 [==============================] - 5s 52ms/step - loss: 3.1562 - accuracy: 0.0814 - val_loss: 3.1744 - val_accuracy: 0.0661\n",
      "Epoch 3/10\n",
      "104/104 [==============================] - 6s 54ms/step - loss: 2.8922 - accuracy: 0.1626 - val_loss: 3.1459 - val_accuracy: 0.0793\n",
      "Epoch 4/10\n",
      "104/104 [==============================] - 6s 56ms/step - loss: 2.3893 - accuracy: 0.2987 - val_loss: 3.1356 - val_accuracy: 0.1286\n",
      "Epoch 5/10\n",
      "104/104 [==============================] - 6s 58ms/step - loss: 1.7039 - accuracy: 0.4883 - val_loss: 3.3455 - val_accuracy: 0.1538\n",
      "Epoch 6/10\n",
      "104/104 [==============================] - 6s 59ms/step - loss: 1.0498 - accuracy: 0.6944 - val_loss: 3.7909 - val_accuracy: 0.1502\n",
      "Epoch 7/10\n",
      "104/104 [==============================] - 6s 55ms/step - loss: 0.5681 - accuracy: 0.8434 - val_loss: 4.2359 - val_accuracy: 0.1647\n",
      "Epoch 8/10\n",
      "104/104 [==============================] - 6s 54ms/step - loss: 0.2821 - accuracy: 0.9327 - val_loss: 5.0818 - val_accuracy: 0.1466\n",
      "Epoch 9/10\n",
      "104/104 [==============================] - 6s 57ms/step - loss: 0.1365 - accuracy: 0.9721 - val_loss: 5.3668 - val_accuracy: 0.1587\n",
      "Epoch 10/10\n",
      "104/104 [==============================] - 6s 60ms/step - loss: 0.0689 - accuracy: 0.9907 - val_loss: 5.8618 - val_accuracy: 0.1623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b88aec6d30>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData] *",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
