{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SyphfjQm4pFe"
   },
   "source": [
    "## Notebook for tuning a CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3I7Y4tK4dOf"
   },
   "source": [
    "**Install HYPERAS libraries first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "krGiUaBFnhZo",
    "outputId": "03129525-6784-4e44-d7a1-61b753f93d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hyperas\n",
      "  Downloading https://files.pythonhosted.org/packages/04/34/87ad6ffb42df9c1fa9c4c906f65813d42ad70d68c66af4ffff048c228cd4/hyperas-0.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.0.7)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.3)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from hyperas) (1.0.0)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from hyperas) (2.4.3)\n",
      "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (from hyperas) (0.1.2)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from hyperas) (5.6.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (2.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.1 in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.3.3)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat->hyperas) (4.6.3)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.2.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (5.3.1)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.10.1)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (4.7.7)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->hyperas) (7.5.1)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (3.13)\n",
      "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (2.10.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->hyperas) (1.18.5)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (3.11.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (4.41.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (2.5)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (0.16.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt->hyperas) (1.15.0)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.6.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.6.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (1.4.2)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (2.11.2)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->hyperas) (3.2.1)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.1->nbformat->hyperas) (4.4.2)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.5.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (1.0.18)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->hyperas) (5.3.5)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (0.9.1)\n",
      "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->hyperas) (5.1.1)\n",
      "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (19.0.2)\n",
      "Requirement already satisfied: qtpy in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->hyperas) (1.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->hyperas) (3.5.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->hyperas) (1.1.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (20.4)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->hyperas) (0.5.1)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.8.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (50.3.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->hyperas) (0.7.5)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->hyperas) (0.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->hyperas) (2.8.1)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.8.1->notebook->jupyter->hyperas) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->bleach->nbconvert->hyperas) (2.4.7)\n",
      "Installing collected packages: hyperas\n",
      "Successfully installed hyperas-0.4.1\n",
      "Requirement already satisfied: hyperopt in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.4.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from hyperopt) (4.41.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt) (2.5)\n",
      "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt) (3.11.0)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt) (0.16.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.18.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt) (1.15.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt) (4.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperas\n",
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQc0lpvm4Vaz"
   },
   "source": [
    "**Load libraries and modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9J2_H9oV6nj"
   },
   "outputs": [],
   "source": [
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.backend import clear_session\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tS9ZBDIx4OZv"
   },
   "source": [
    "**Mount google drive to read numpy array files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rsD-229Jn_xt",
    "outputId": "583bb05e-b5ee-4052-94db-a8cd4c6d1c4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZdDAsBz4CzB"
   },
   "source": [
    "**HYPERAS data function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kxy91A7HRtc-"
   },
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "\n",
    "def data():\n",
    "  # load array from numpy array files\n",
    "  X_train = load('/content/drive/My Drive/images_for_training/X_train.npy')\n",
    "  y_train = load('/content/drive/My Drive/images_for_training/y_train.npy')\n",
    "  X_test = load('/content/drive/My Drive/images_for_training/X_test.npy')\n",
    "  y_test = load('/content/drive/My Drive/images_for_training/y_test.npy')\n",
    "  \n",
    "  return X_train, y_train, X_test, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjsvp50x37Z9"
   },
   "source": [
    "**HYPERAS model function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-ymevS3WXY6"
   },
   "outputs": [],
   "source": [
    "def model(x_train, y_train, x_test, y_test):  \n",
    "\n",
    "    clear_session()\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            {{choice([26, 52])}},\n",
    "            kernel_size = {{choice([(3, 3),(5,5)])}},\n",
    "            padding = 'valid',\n",
    "            activation = 'relu',\n",
    "            input_shape = (200, 200, 1)\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            {{choice([26, 52])}}, \n",
    "            kernel_size = {{choice([(3, 3),(5,5)])}},\n",
    "            padding = \"valid\",\n",
    "            activation='relu'\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        MaxPooling2D(\n",
    "            pool_size = {{choice([(2, 2),(4,4)])}}\n",
    "        )\n",
    "    )\n",
    "    ### Should try removing these ###\n",
    "    #################################\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            {{choice([20, 40])}},\n",
    "            kernel_size = {{choice([(3, 3),(5,5)])}},\n",
    "            padding = \"valid\",\n",
    "            activation='relu'\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        MaxPooling2D(\n",
    "            pool_size = {{choice([(2, 2),(4,4)])}}\n",
    "        )\n",
    "    )\n",
    "    #################################\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            {{uniform(0, 1)}}\n",
    "        )\n",
    "    )\n",
    "    model.add(Flatten())\n",
    "    model.add(\n",
    "        Dense(\n",
    "            {{choice(\n",
    "                [256, 512])}}\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Activation(\n",
    "            {{choice(['relu', 'tanh'])}}\n",
    "        )\n",
    "    )\n",
    "    model.add(\n",
    "        Dropout(\n",
    "            {{uniform(0, 1)}}\n",
    "        )\n",
    "    )\n",
    "    model.add(Dense(26, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "    result = model.fit(X_train, y_train, epochs={{choice([5,10,20])}}, verbose=2, validation_split=0.1, callbacks=[callback])\n",
    "    \n",
    "    json_string = model.to_json()\n",
    "\n",
    "    #get the highest validation accuracy of the training epochs\n",
    "    validation_acc = np.amax(result.history['val_accuracy']) \n",
    "    print('Best validation acc of epoch:', validation_acc)\n",
    "\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model':(json_string)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rHSyqS-KHVBd"
   },
   "outputs": [],
   "source": [
    "# Look at how much RAM memory the varibles are using.\n",
    "# import sys\n",
    "# # These are the usual ipython objects, including this one you are creating\n",
    "# ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "# # Get a sorted list of the objects and their sizes\n",
    "# sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAh59RsY_y-m"
   },
   "outputs": [],
   "source": [
    "# Testing how many parameters are being generated by the model.\n",
    "# model = Sequential()\n",
    "# model.add(\n",
    "#         Conv2D(\n",
    "#             64,\n",
    "#             kernel_size = (3,3),\n",
    "#             padding = 'valid',\n",
    "#             activation = 'relu',\n",
    "#             input_shape = (200, 200, 1)\n",
    "#         )\n",
    "#     )\n",
    "# model.add(\n",
    "#         Conv2D(\n",
    "#             64, \n",
    "#             kernel_size = (3, 3),\n",
    "#             padding = \"valid\",\n",
    "#             activation='relu'\n",
    "#         )\n",
    "#     )\n",
    "\n",
    "# model.add(\n",
    "#         MaxPooling2D(\n",
    "#             pool_size = (2, 2)\n",
    "#         )\n",
    "#     )\n",
    "# model.add(\n",
    "#         Conv2D(\n",
    "#             20, \n",
    "#             kernel_size = (3, 3),\n",
    "#             padding = \"valid\",\n",
    "#             activation='relu'\n",
    "#         )\n",
    "#     )\n",
    "# model.add(\n",
    "#         MaxPooling2D(\n",
    "#             pool_size = (4, 4)\n",
    "#         )\n",
    "#     )\n",
    "# model.add(\n",
    "#         Dropout(\n",
    "#             .25\n",
    "#         )\n",
    "#     )\n",
    "# model.add(Flatten())\n",
    "# model.add(\n",
    "#         Dense(\n",
    "#             256\n",
    "#         )\n",
    "#     )\n",
    "# model.add(\n",
    "#         Activation(\n",
    "#             'tanh'\n",
    "#         )\n",
    "#     )\n",
    "# model.add(\n",
    "#         Dropout(\n",
    "#             .25\n",
    "#         )\n",
    "#     )\n",
    "# model.add(Dense(26, activation='softmax'))\n",
    "\n",
    "# Print the summary of the model.\n",
    "# model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6c-gTJmH6Au"
   },
   "outputs": [],
   "source": [
    "# Compile the model with testing data.\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Fit the model with test data\n",
    "# result = model.fit(X_test, y_test, epochs=50, verbose=2, validation_split=0.1, callbacks=[callback])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz3dzoRB3Ahg"
   },
   "source": [
    "Workaround to allow the notebook name to be recognized by HYPERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUJq5MVjXSTA"
   },
   "outputs": [],
   "source": [
    "# See: https://stackoverflow.com/questions/49920031/get-the-path-of-the-notebook-on-google-colab\n",
    "# Install the PyDrive wrapper & import libraries.\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "# Copy/download the file\n",
    "fid = drive.ListFile({'q':\"title='HyperasModelTuning.ipynb'\"}).GetList()[0]['id']\n",
    "f = drive.CreateFile({'id': fid})\n",
    "f.GetContentFile('HyperasModelTuning.ipynb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDQvxx4k2syB"
   },
   "source": [
    "**Run the HYPERAS optimization process**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "AR0HkQPlWmlZ",
    "outputId": "e7c9ef4a-7d79-47e9-d75d-3e6ebe630514"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.datasets import mnist\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.utils import np_utils\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Conv2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.callbacks import EarlyStopping\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import MaxPooling2D\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.layers import Flatten\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.preprocessing import image\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.utils import to_categorical\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tensorflow.keras.backend import clear_session\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from tqdm import tqdm\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from google.colab import drive\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from numpy import load\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from pydrive.auth import GoogleAuth\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from pydrive.drive import GoogleDrive\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from google.colab import auth\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from oauth2client.client import GoogleCredentials\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Conv2D': hp.choice('Conv2D', [26, 52]),\n",
      "        'kernel_size': hp.choice('kernel_size', [(3, 3),(5,5)]),\n",
      "        'Conv2D_1': hp.choice('Conv2D_1', [26, 52]),\n",
      "        'kernel_size_1': hp.choice('kernel_size_1', [(3, 3),(5,5)]),\n",
      "        'pool_size': hp.choice('pool_size', [(2, 2),(4,4)]),\n",
      "        'Conv2D_2': hp.choice('Conv2D_2', [20, 40]),\n",
      "        'kernel_size_2': hp.choice('kernel_size_2', [(3, 3),(5,5)]),\n",
      "        'pool_size_1': hp.choice('pool_size_1', [(2, 2),(4,4)]),\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense': hp.choice('Dense', \n",
      "                [256, 512]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'tanh']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'epochs': hp.choice('epochs', [20,50,100]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "  1: \n",
      "  2: # load array\n",
      "  3: X_train = load('/content/drive/My Drive/images_for_training/X_train.npy')\n",
      "  4: y_train = load('/content/drive/My Drive/images_for_training/y_train.npy')\n",
      "  5: X_test = load('/content/drive/My Drive/images_for_training/X_test.npy')\n",
      "  6: y_test = load('/content/drive/My Drive/images_for_training/y_test.npy')\n",
      "  7: \n",
      "  8: # print the array\n",
      "  9: print(y_train)\n",
      " 10: print(y_test)\n",
      " 11: \n",
      " 12: \n",
      " 13: \n",
      " 14: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     model = Sequential()\n",
      "   4:     model.add(\n",
      "   5:         Conv2D(\n",
      "   6:             space['Conv2D'],\n",
      "   7:             kernel_size = space['kernel_size'],\n",
      "   8:             padding = 'valid',\n",
      "   9:             activation = 'relu',\n",
      "  10:             input_shape = (200, 200, 1)\n",
      "  11:         )\n",
      "  12:     )\n",
      "  13:     model.add(\n",
      "  14:         Conv2D(\n",
      "  15:             space['Conv2D_1'], \n",
      "  16:             kernel_size = space['kernel_size_1'],\n",
      "  17:             padding = \"valid\",\n",
      "  18:             activation='relu'\n",
      "  19:         )\n",
      "  20:     )\n",
      "  21:     model.add(\n",
      "  22:         MaxPooling2D(\n",
      "  23:             pool_size = space['pool_size']\n",
      "  24:         )\n",
      "  25:     )\n",
      "  26:     model.add(\n",
      "  27:         Conv2D(\n",
      "  28:             space['Conv2D_2'],\n",
      "  29:             kernel_size = space['kernel_size_2'],\n",
      "  30:             padding = \"valid\",\n",
      "  31:             activation='relu'\n",
      "  32:         )\n",
      "  33:     )\n",
      "  34:     model.add(\n",
      "  35:         MaxPooling2D(\n",
      "  36:             pool_size = space['pool_size_1']\n",
      "  37:         )\n",
      "  38:     )\n",
      "  39:     model.add(\n",
      "  40:         Dropout(\n",
      "  41:             space['Dropout']\n",
      "  42:         )\n",
      "  43:     )\n",
      "  44:     model.add(Flatten())\n",
      "  45:     model.add(\n",
      "  46:         Dense(\n",
      "  47:             space['Dense']\n",
      "  48:         )\n",
      "  49:     )\n",
      "  50:     model.add(\n",
      "  51:         Activation(\n",
      "  52:             space['Activation']\n",
      "  53:         )\n",
      "  54:     )\n",
      "  55:     model.add(\n",
      "  56:         Dropout(\n",
      "  57:             space['Dropout_1']\n",
      "  58:         )\n",
      "  59:     )\n",
      "  60:     model.add(Dense(26, activation='softmax'))\n",
      "  61: \n",
      "  62:     model.summary()\n",
      "  63: \n",
      "  64:     model.compile(optimizer='adam',\n",
      "  65:               loss='categorical_crossentropy',\n",
      "  66:               metrics=['accuracy'])\n",
      "  67:     \n",
      "  68:     callback = EarlyStopping(monitor='val_loss', patience=3)\n",
      "  69: \n",
      "  70:     result = model.fit(X_train, y_train, epochs=space['epochs'], verbose=2, validation_split=0.1, callbacks=[callback])\n",
      "  71:     \n",
      "  72:     json_string = model.to_json()\n",
      "  73: \n",
      "  74:     #get the highest validation accuracy of the training epochs\n",
      "  75:     validation_acc = np.amax(result.history['val_accuracy']) \n",
      "  76:     print('Best validation acc of epoch:', validation_acc)\n",
      "  77: \n",
      "  78:     clear_session()\n",
      "  79: \n",
      "  80:     return {'loss': -validation_acc, 'status': STATUS_OK, 'model':(json_string)}\n",
      "  81: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 196, 196, 52)      1352      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 194, 194, 52)      24388     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 52)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 46, 46, 40)        18760     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 40)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 23, 40)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21160)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               5417216   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                6682      \n",
      "=================================================================\n",
      "Total params: 5,468,398\n",
      "Trainable params: 5,468,398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "  0%|          | 0/5 [00:07<?, ?it/s, best loss: ?]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0048s vs `on_train_batch_end` time: 0.0376s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_test_batch_end` time: 0.0113s). Check your callbacks.\n",
      "1755/1755 - 75s - loss: 2.0155 - accuracy: 0.3637 - val_loss: 0.7396 - val_accuracy: 0.8112\n",
      "\n",
      "Epoch 2/50\n",
      "1755/1755 - 75s - loss: 1.0082 - accuracy: 0.6436 - val_loss: 0.4058 - val_accuracy: 0.9008\n",
      "\n",
      "Epoch 3/50\n",
      "1755/1755 - 75s - loss: 0.7626 - accuracy: 0.7255 - val_loss: 0.2804 - val_accuracy: 0.9431\n",
      "\n",
      "Epoch 4/50\n",
      "1755/1755 - 75s - loss: 0.6276 - accuracy: 0.7741 - val_loss: 0.2154 - val_accuracy: 0.9551\n",
      "\n",
      "Epoch 5/50\n",
      "1755/1755 - 75s - loss: 0.5446 - accuracy: 0.8030 - val_loss: 0.1778 - val_accuracy: 0.9593\n",
      "\n",
      "Epoch 6/50\n",
      "1755/1755 - 75s - loss: 0.5006 - accuracy: 0.8202 - val_loss: 0.1638 - val_accuracy: 0.9684\n",
      "\n",
      "Epoch 7/50\n",
      "1755/1755 - 75s - loss: 0.4573 - accuracy: 0.8346 - val_loss: 0.1418 - val_accuracy: 0.9668\n",
      "\n",
      "Epoch 8/50\n",
      "1755/1755 - 75s - loss: 0.4248 - accuracy: 0.8483 - val_loss: 0.1194 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 9/50\n",
      "1755/1755 - 75s - loss: 0.3921 - accuracy: 0.8586 - val_loss: 0.1071 - val_accuracy: 0.9755\n",
      "\n",
      "Epoch 10/50\n",
      "1755/1755 - 75s - loss: 0.3775 - accuracy: 0.8660 - val_loss: 0.0947 - val_accuracy: 0.9817\n",
      "\n",
      "Epoch 11/50\n",
      "1755/1755 - 75s - loss: 0.3676 - accuracy: 0.8699 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
      "\n",
      "Epoch 12/50\n",
      "1755/1755 - 75s - loss: 0.3546 - accuracy: 0.8745 - val_loss: 0.0848 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 13/50\n",
      "1755/1755 - 75s - loss: 0.3381 - accuracy: 0.8809 - val_loss: 0.0827 - val_accuracy: 0.9864\n",
      "\n",
      "Epoch 14/50\n",
      "1755/1755 - 75s - loss: 0.3273 - accuracy: 0.8852 - val_loss: 0.0643 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 15/50\n",
      "1755/1755 - 75s - loss: 0.3127 - accuracy: 0.8896 - val_loss: 0.0648 - val_accuracy: 0.9856\n",
      "\n",
      "Epoch 16/50\n",
      "1755/1755 - 75s - loss: 0.3051 - accuracy: 0.8930 - val_loss: 0.0794 - val_accuracy: 0.9755\n",
      "\n",
      "Epoch 17/50\n",
      "1755/1755 - 75s - loss: 0.3040 - accuracy: 0.8948 - val_loss: 0.0507 - val_accuracy: 0.9910\n",
      "\n",
      "Epoch 18/50\n",
      "1755/1755 - 75s - loss: 0.2917 - accuracy: 0.8993 - val_loss: 0.0529 - val_accuracy: 0.9883\n",
      "\n",
      "Epoch 19/50\n",
      "1755/1755 - 75s - loss: 0.2883 - accuracy: 0.9011 - val_loss: 0.0413 - val_accuracy: 0.9918\n",
      "\n",
      "Epoch 20/50\n",
      "1755/1755 - 75s - loss: 0.2776 - accuracy: 0.9038 - val_loss: 0.0643 - val_accuracy: 0.9901\n",
      "\n",
      "Epoch 21/50\n",
      "1755/1755 - 75s - loss: 0.2743 - accuracy: 0.9048 - val_loss: 0.0404 - val_accuracy: 0.9937\n",
      "\n",
      "Epoch 22/50\n",
      "1755/1755 - 75s - loss: 0.2670 - accuracy: 0.9090 - val_loss: 0.0447 - val_accuracy: 0.9920\n",
      "\n",
      "Epoch 23/50\n",
      "1755/1755 - 75s - loss: 0.2666 - accuracy: 0.9086 - val_loss: 0.0465 - val_accuracy: 0.9859\n",
      "\n",
      "Epoch 24/50\n",
      "1755/1755 - 75s - loss: 0.2546 - accuracy: 0.9117 - val_loss: 0.0501 - val_accuracy: 0.9862\n",
      "\n",
      "Best validation acc of epoch:\n",
      "0.9937499761581421\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 198, 198, 52)      520       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 196, 196, 26)      12194     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 98, 98, 26)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 94, 94, 40)        26040     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 47, 47, 40)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 47, 47, 40)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 88360)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               45240832  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 45,292,924\n",
      "Trainable params: 45,292,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 20%|██        | 1/5 [30:10<2:00:41, 1810.40s/it, best loss: -0.9937499761581421]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0043s vs `on_train_batch_end` time: 0.0369s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_test_batch_end` time: 0.0104s). Check your callbacks.\n",
      "1755/1755 - 74s - loss: 3.2762 - accuracy: 0.0393 - val_loss: 3.2586 - val_accuracy: 0.0417\n",
      "\n",
      "Epoch 2/50\n",
      "1755/1755 - 74s - loss: 3.2684 - accuracy: 0.0374 - val_loss: 3.2585 - val_accuracy: 0.0396\n",
      "\n",
      "Epoch 3/50\n",
      "1755/1755 - 74s - loss: 3.2683 - accuracy: 0.0384 - val_loss: 3.2590 - val_accuracy: 0.0418\n",
      "\n",
      "Epoch 4/50\n",
      "1755/1755 - 74s - loss: 3.2688 - accuracy: 0.0389 - val_loss: 3.2588 - val_accuracy: 0.0380\n",
      "\n",
      "Epoch 5/50\n",
      "1755/1755 - 74s - loss: 3.2680 - accuracy: 0.0390 - val_loss: 3.2596 - val_accuracy: 0.0333\n",
      "\n",
      "Best validation acc of epoch:\n",
      "0.041826922446489334\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 196, 196, 26)      676       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 194, 194, 52)      12220     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 97, 97, 52)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 95, 95, 40)        18760     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 40)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 23, 40)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21160)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               10834432  \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 10,879,426\n",
      "Trainable params: 10,879,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      " 40%|████      | 2/5 [36:21<1:08:55, 1378.40s/it, best loss: -0.9937499761581421]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0035s vs `on_train_batch_end` time: 0.0310s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_test_batch_end` time: 0.0094s). Check your callbacks.\n",
      "1755/1755 - 63s - loss: 1.1705 - accuracy: 0.6300 - val_loss: 0.2457 - val_accuracy: 0.9216\n",
      "\n",
      "Epoch 2/50\n",
      "1755/1755 - 63s - loss: 0.3611 - accuracy: 0.8758 - val_loss: 0.1058 - val_accuracy: 0.9729\n",
      "\n",
      "Epoch 3/50\n",
      "1755/1755 - 63s - loss: 0.2317 - accuracy: 0.9197 - val_loss: 0.0487 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 4/50\n",
      "1755/1755 - 63s - loss: 0.1891 - accuracy: 0.9355 - val_loss: 0.0462 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 5/50\n",
      "1755/1755 - 63s - loss: 0.1572 - accuracy: 0.9479 - val_loss: 0.0340 - val_accuracy: 0.9912\n",
      "\n",
      "Epoch 6/50\n",
      "1755/1755 - 63s - loss: 0.1336 - accuracy: 0.9544 - val_loss: 0.0279 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 7/50\n",
      "1755/1755 - 63s - loss: 0.1149 - accuracy: 0.9616 - val_loss: 0.0172 - val_accuracy: 0.9962\n",
      "\n",
      "Epoch 8/50\n",
      "1755/1755 - 63s - loss: 0.1102 - accuracy: 0.9631 - val_loss: 0.0220 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 9/50\n",
      "1755/1755 - 63s - loss: 0.0945 - accuracy: 0.9686 - val_loss: 0.0225 - val_accuracy: 0.9941\n",
      "\n",
      "Epoch 10/50\n",
      "1755/1755 - 62s - loss: 0.0892 - accuracy: 0.9703 - val_loss: 0.0159 - val_accuracy: 0.9965\n",
      "\n",
      "Epoch 11/50\n",
      "1755/1755 - 62s - loss: 0.0847 - accuracy: 0.9716 - val_loss: 0.0092 - val_accuracy: 0.9979\n",
      "\n",
      "Epoch 12/50\n",
      "1755/1755 - 63s - loss: 0.0820 - accuracy: 0.9735 - val_loss: 0.0172 - val_accuracy: 0.9949\n",
      "\n",
      "Epoch 13/50\n",
      "1755/1755 - 63s - loss: 0.0736 - accuracy: 0.9755 - val_loss: 0.0122 - val_accuracy: 0.9965\n",
      "\n",
      "Epoch 14/50\n",
      "1755/1755 - 63s - loss: 0.0738 - accuracy: 0.9760 - val_loss: 0.0080 - val_accuracy: 0.9981\n",
      "\n",
      "Epoch 15/50\n",
      "1755/1755 - 62s - loss: 0.0673 - accuracy: 0.9787 - val_loss: 0.0127 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 16/50\n",
      "1755/1755 - 62s - loss: 0.0618 - accuracy: 0.9801 - val_loss: 0.0113 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 17/50\n",
      "1755/1755 - 62s - loss: 0.0619 - accuracy: 0.9802 - val_loss: 0.0103 - val_accuracy: 0.9973\n",
      "\n",
      "Best validation acc of epoch:\n",
      "0.9980769157409668\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 196, 196, 52)      1352      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 192, 192, 26)      33826     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 48, 48, 26)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 44, 44, 20)        13020     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 20)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 11, 11, 20)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2420)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1239552   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                13338     \n",
      "=================================================================\n",
      "Total params: 1,301,088\n",
      "Trainable params: 1,301,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      " 60%|██████    | 3/5 [54:07<42:49, 1284.68s/it, best loss: -0.9980769157409668]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0049s vs `on_train_batch_end` time: 0.0352s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0032s vs `on_test_batch_end` time: 0.0085s). Check your callbacks.\n",
      "1755/1755 - 72s - loss: 3.2632 - accuracy: 0.0387 - val_loss: 3.2609 - val_accuracy: 0.0369\n",
      "\n",
      "Epoch 2/100\n",
      "1755/1755 - 72s - loss: 3.2616 - accuracy: 0.0384 - val_loss: 3.2613 - val_accuracy: 0.0333\n",
      "\n",
      "Epoch 3/100\n",
      "1755/1755 - 72s - loss: 3.2615 - accuracy: 0.0395 - val_loss: 3.2605 - val_accuracy: 0.0357\n",
      "\n",
      "Epoch 4/100\n",
      "1755/1755 - 72s - loss: 3.2620 - accuracy: 0.0383 - val_loss: 3.2603 - val_accuracy: 0.0380\n",
      "\n",
      "Epoch 5/100\n",
      "1755/1755 - 72s - loss: 3.2621 - accuracy: 0.0377 - val_loss: 3.2608 - val_accuracy: 0.0364\n",
      "\n",
      "Epoch 6/100\n",
      "1755/1755 - 72s - loss: 3.2621 - accuracy: 0.0388 - val_loss: 3.2605 - val_accuracy: 0.0380\n",
      "\n",
      "Epoch 7/100\n",
      "1755/1755 - 72s - loss: 3.2619 - accuracy: 0.0384 - val_loss: 3.2597 - val_accuracy: 0.0380\n",
      "\n",
      "Epoch 8/100\n",
      "1755/1755 - 72s - loss: 3.2622 - accuracy: 0.0384 - val_loss: 3.2595 - val_accuracy: 0.0412\n",
      "\n",
      "Epoch 9/100\n",
      "1755/1755 - 72s - loss: 3.2622 - accuracy: 0.0381 - val_loss: 3.2600 - val_accuracy: 0.0372\n",
      "\n",
      "Epoch 10/100\n",
      "1755/1755 - 73s - loss: 3.2625 - accuracy: 0.0387 - val_loss: 3.2593 - val_accuracy: 0.0417\n",
      "\n",
      "Epoch 11/100\n",
      "1755/1755 - 72s - loss: 3.2624 - accuracy: 0.0383 - val_loss: 3.2599 - val_accuracy: 0.0333\n",
      "\n",
      "Epoch 12/100\n",
      "1755/1755 - 72s - loss: 3.2625 - accuracy: 0.0380 - val_loss: 3.2603 - val_accuracy: 0.0386\n",
      "\n",
      "Epoch 13/100\n",
      "1755/1755 - 72s - loss: 3.2630 - accuracy: 0.0373 - val_loss: 3.2598 - val_accuracy: 0.0364\n",
      "\n",
      "Best validation acc of epoch:\n",
      "0.0416666679084301\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 196, 196, 52)      1352      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 194, 194, 52)      24388     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 97, 97, 52)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 93, 93, 20)        26020     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 23, 23, 20)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 23, 23, 20)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10580)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2708736   \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 26)                6682      \n",
      "=================================================================\n",
      "Total params: 2,767,178\n",
      "Trainable params: 2,767,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      " 80%|████████  | 4/5 [1:09:47<19:41, 1181.54s/it, best loss: -0.9980769157409668]WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0039s vs `on_train_batch_end` time: 0.0433s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0026s vs `on_test_batch_end` time: 0.0125s). Check your callbacks.\n",
      "1755/1755 - 85s - loss: 2.4305 - accuracy: 0.2561 - val_loss: 1.0908 - val_accuracy: 0.6954\n",
      "\n",
      "Epoch 2/100\n",
      "1755/1755 - 85s - loss: 1.3803 - accuracy: 0.5374 - val_loss: 0.6039 - val_accuracy: 0.8279\n",
      "\n",
      "Epoch 3/100\n",
      "1755/1755 - 85s - loss: 1.0292 - accuracy: 0.6441 - val_loss: 0.3949 - val_accuracy: 0.8832\n",
      "\n",
      "Epoch 4/100\n",
      "1755/1755 - 85s - loss: 0.8433 - accuracy: 0.7102 - val_loss: 0.2978 - val_accuracy: 0.9269\n",
      "\n",
      "Epoch 5/100\n",
      "1755/1755 - 85s - loss: 0.7159 - accuracy: 0.7510 - val_loss: 0.2205 - val_accuracy: 0.9474\n",
      "\n",
      "Epoch 6/100\n",
      "1755/1755 - 85s - loss: 0.6270 - accuracy: 0.7830 - val_loss: 0.1562 - val_accuracy: 0.9644\n",
      "\n",
      "Epoch 7/100\n",
      "1755/1755 - 85s - loss: 0.5647 - accuracy: 0.8036 - val_loss: 0.1342 - val_accuracy: 0.9647\n",
      "\n",
      "Epoch 8/100\n",
      "1755/1755 - 85s - loss: 0.5130 - accuracy: 0.8213 - val_loss: 0.1301 - val_accuracy: 0.9649\n",
      "\n",
      "Epoch 9/100\n",
      "1755/1755 - 85s - loss: 0.4735 - accuracy: 0.8349 - val_loss: 0.0972 - val_accuracy: 0.9758\n",
      "\n",
      "Epoch 10/100\n",
      "1755/1755 - 85s - loss: 0.4536 - accuracy: 0.8422 - val_loss: 0.0840 - val_accuracy: 0.9780\n",
      "\n",
      "Epoch 11/100\n",
      "1755/1755 - 85s - loss: 0.4331 - accuracy: 0.8491 - val_loss: 0.0914 - val_accuracy: 0.9708\n",
      "\n",
      "Epoch 12/100\n",
      "1755/1755 - 85s - loss: 0.4190 - accuracy: 0.8542 - val_loss: 0.0702 - val_accuracy: 0.9825\n",
      "\n",
      "Epoch 13/100\n",
      "1755/1755 - 85s - loss: 0.4009 - accuracy: 0.8619 - val_loss: 0.0640 - val_accuracy: 0.9822\n",
      "\n",
      "Epoch 14/100\n",
      "1755/1755 - 85s - loss: 0.3854 - accuracy: 0.8659 - val_loss: 0.1019 - val_accuracy: 0.9657\n",
      "\n",
      "Epoch 15/100\n",
      "1755/1755 - 85s - loss: 0.3725 - accuracy: 0.8718 - val_loss: 0.0564 - val_accuracy: 0.9838\n",
      "\n",
      "Epoch 16/100\n",
      "1755/1755 - 85s - loss: 0.3620 - accuracy: 0.8724 - val_loss: 0.0491 - val_accuracy: 0.9877\n",
      "\n",
      "Epoch 17/100\n",
      "1755/1755 - 85s - loss: 0.3611 - accuracy: 0.8750 - val_loss: 0.0475 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 18/100\n",
      "1755/1755 - 85s - loss: 0.3464 - accuracy: 0.8778 - val_loss: 0.0688 - val_accuracy: 0.9800\n",
      "\n",
      "Epoch 19/100\n",
      "1755/1755 - 85s - loss: 0.3416 - accuracy: 0.8811 - val_loss: 0.0468 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 20/100\n",
      "1755/1755 - 85s - loss: 0.3378 - accuracy: 0.8835 - val_loss: 0.0438 - val_accuracy: 0.9862\n",
      "\n",
      "Epoch 21/100\n",
      "1755/1755 - 85s - loss: 0.3369 - accuracy: 0.8832 - val_loss: 0.0614 - val_accuracy: 0.9804\n",
      "\n",
      "Epoch 22/100\n",
      "1755/1755 - 85s - loss: 0.3247 - accuracy: 0.8857 - val_loss: 0.0456 - val_accuracy: 0.9878\n",
      "\n",
      "Epoch 23/100\n",
      "1755/1755 - 85s - loss: 0.3286 - accuracy: 0.8877 - val_loss: 0.0414 - val_accuracy: 0.9870\n",
      "\n",
      "Epoch 24/100\n",
      "1755/1755 - 85s - loss: 0.3245 - accuracy: 0.8880 - val_loss: 0.0473 - val_accuracy: 0.9861\n",
      "\n",
      "Epoch 25/100\n",
      "1755/1755 - 85s - loss: 0.3193 - accuracy: 0.8899 - val_loss: 0.0338 - val_accuracy: 0.9917\n",
      "\n",
      "Epoch 26/100\n",
      "1755/1755 - 85s - loss: 0.3104 - accuracy: 0.8937 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
      "\n",
      "Epoch 27/100\n",
      "1755/1755 - 85s - loss: 0.3142 - accuracy: 0.8918 - val_loss: 0.0358 - val_accuracy: 0.9893\n",
      "\n",
      "Epoch 28/100\n",
      "1755/1755 - 85s - loss: 0.3088 - accuracy: 0.8941 - val_loss: 0.0418 - val_accuracy: 0.9867\n",
      "\n",
      "Best validation acc of epoch:\n",
      "0.9916666746139526\n",
      "100%|██████████| 5/5 [1:49:37<00:00, 1315.56s/it, best loss: -0.9980769157409668]\n"
     ]
    }
   ],
   "source": [
    "# Get best parameters to train model\n",
    "best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=data,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5, # should try to use 3\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='HyperasModelTuning')\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = data()\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(X_test, Y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R6bTka1E2jH8"
   },
   "source": [
    "**Save the tuned model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYZXL8lcIRQl"
   },
   "outputs": [],
   "source": [
    "model.save('/content/drive/My Drive/model/tuned_model_1.h5', save_format='h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RsfZ0mV4ha0V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "HyperasModelTuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
